{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Inception V3 Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.applications import inception_v3\n",
    "from keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense,Flatten,Dropout\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.optimizers import Adam, RMSprop , SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir =r'D:\\datasets'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir,'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "conv_base = inception_v3.InceptionV3(weights = 'imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "model = Sequential()\n",
    "for layer in conv_base.layers[:-12]:\n",
    "  layer.trainable=False\n",
    "\n",
    "x = conv_base.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "predictions = layers.Dense(5, activation='softmax')(x)\n",
    "model = models.Model(inputs=conv_base.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29978 images belonging to 5 classes.\n",
      "Found 9788 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                rotation_range=40,\n",
    "                                width_shift_range=0.2,\n",
    "                                height_shift_range=0.2,\n",
    "                                shear_range=0.2,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                target_size=(224, 224),\n",
    "                                batch_size=10,\n",
    "                                class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
    "                                target_size=(224, 224),\n",
    "                                batch_size=10,\n",
    "                                class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abir': 0, 'bobi': 1, 'empty': 2, 'rafi': 3, 'unknown': 4}\n"
     ]
    }
   ],
   "source": [
    "labels=(train_generator.class_indices)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "64/64 [==============================] - 17s 270ms/step - loss: 1.5511 - acc: 0.2891 - auc_1: 0.6256 - sensitivity_at_specificity_1: 0.7063 - val_loss: 1.2341 - val_acc: 0.5094 - val_auc_1: 0.8106 - val_sensitivity_at_specificity_1: 0.8813\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.50937, saving model to inception_custom_v3_weights_all.best.hdf5\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 10s 160ms/step - loss: 1.4510 - acc: 0.3875 - auc_1: 0.7057 - sensitivity_at_specificity_1: 0.7891 - val_loss: 1.6643 - val_acc: 0.6000 - val_auc_1: 0.8447 - val_sensitivity_at_specificity_1: 0.8687\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.50937 to 0.60000, saving model to inception_custom_v3_weights_all.best.hdf5\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 10s 163ms/step - loss: 1.3482 - acc: 0.4703 - auc_1: 0.7746 - sensitivity_at_specificity_1: 0.8453 - val_loss: 1.1982 - val_acc: 0.7297 - val_auc_1: 0.9081 - val_sensitivity_at_specificity_1: 0.9094\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.60000 to 0.72969, saving model to inception_custom_v3_weights_all.best.hdf5\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 10s 161ms/step - loss: 1.2773 - acc: 0.5359 - auc_1: 0.8056 - sensitivity_at_specificity_1: 0.8687 - val_loss: 0.7972 - val_acc: 0.7359 - val_auc_1: 0.8970 - val_sensitivity_at_specificity_1: 0.9000\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.72969 to 0.73594, saving model to inception_custom_v3_weights_all.best.hdf5\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 10s 164ms/step - loss: 1.1377 - acc: 0.6250 - auc_1: 0.8634 - sensitivity_at_specificity_1: 0.9234 - val_loss: 0.8607 - val_acc: 0.7750 - val_auc_1: 0.9222 - val_sensitivity_at_specificity_1: 0.9594\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.73594 to 0.77500, saving model to inception_custom_v3_weights_all.best.hdf5\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 11s 165ms/step - loss: 1.0579 - acc: 0.6438 - auc_1: 0.8824 - sensitivity_at_specificity_1: 0.9563 - val_loss: 0.3509 - val_acc: 0.8000 - val_auc_1: 0.9381 - val_sensitivity_at_specificity_1: 0.9781\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.77500 to 0.80000, saving model to inception_custom_v3_weights_all.best.hdf5\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 10s 162ms/step - loss: 0.8964 - acc: 0.7016 - auc_1: 0.9234 - sensitivity_at_specificity_1: 0.9766 - val_loss: 1.1116 - val_acc: 0.8109 - val_auc_1: 0.9520 - val_sensitivity_at_specificity_1: 0.9906\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.80000 to 0.81094, saving model to inception_custom_v3_weights_all.best.hdf5\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 10s 159ms/step - loss: 0.8437 - acc: 0.7453 - auc_1: 0.9331 - sensitivity_at_specificity_1: 0.9859 - val_loss: 0.6557 - val_acc: 0.8547 - val_auc_1: 0.9606 - val_sensitivity_at_specificity_1: 0.9875\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.81094 to 0.85469, saving model to inception_custom_v3_weights_all.best.hdf5\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 10s 164ms/step - loss: 0.6854 - acc: 0.8009 - auc_1: 0.9616 - sensitivity_at_specificity_1: 0.9906 - val_loss: 0.3908 - val_acc: 0.8281 - val_auc_1: 0.9710 - val_sensitivity_at_specificity_1: 0.9937\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.85469\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 11s 169ms/step - loss: 0.6020 - acc: 0.8188 - auc_1: 0.9704 - sensitivity_at_specificity_1: 0.9969 - val_loss: 0.4199 - val_acc: 0.8078 - val_auc_1: 0.9660 - val_sensitivity_at_specificity_1: 0.9953\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.85469\n"
     ]
    }
   ],
   "source": [
    "from keras.metrics import AUC, SensitivityAtSpecificity\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                                optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "                                metrics=['acc', AUC(), SensitivityAtSpecificity(.5)])\n",
    "\n",
    "\n",
    "filepath = \"inception_custom_v3_weights_all.best.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose =1, save_best_only=True, mode = 'max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                                steps_per_epoch=64,\n",
    "                                epochs=10, \n",
    "                                callbacks=callbacks_list, \n",
    "                                verbose =1, \n",
    "                                validation_data=validation_generator,\n",
    "                                validation_steps=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 133 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "\n",
    "model.load_weights(\"inception_custom_v3_weights_all.best.hdf5\")\n",
    "\n",
    "from keras import optimizers\n",
    "model.compile(loss='categorical_crossentropy',optimizer=optimizers.RMSprop(lr=2e-5),metrics=['acc'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_dir,target_size=(224,224),batch_size=30,class_mode=None, shuffle = False)\n",
    "probabilities = model.predict_generator(test_generator, 968)\n",
    "prob=probabilities[0:968,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import label_binarize\n",
    "labels = np.array([0] * 242 + [1] * 242 + [2] * 242 + [3] * 242 + [4] * 242)\n",
    "y_test = label_binarize(labels, classes=[0, 1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cal = np.argmax(prob, axis = 1)\n",
    "y_score = label_binarize(y_cal, classes=[0, 1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1210, 968]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-690b556899c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_cal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mconfusion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_cal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \"\"\"\n\u001b[1;32m---> 80\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 212\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1210, 968]"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix and test accuracy\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(metrics.accuracy_score(labels,y_cal))\n",
    "confusion = metrics.confusion_matrix(labels,y_cal)\n",
    "print(confusion)\n",
    "\n",
    "from pycm import ConfusionMatrix\n",
    "cm = ConfusionMatrix(actual_vector=labels, predict_vector=y_cal)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision recall curve. The code is mainly adapted from the following link\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "\n",
    "n_classes=5\n",
    "# For each class\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "for i in range(n_classes):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_test[:, i],\n",
    "                                                        y_score[:, i])\n",
    "    average_precision[i] = average_precision_score(y_test[:, i], y_score[:, i])\n",
    "\n",
    "# A \"micro-average\": quantifying score on all classes jointly\n",
    "precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(y_test.ravel(),\n",
    "    y_score.ravel())\n",
    "average_precision[\"micro\"] = average_precision_score(y_test, y_score,\n",
    "                                                     average=\"micro\")\n",
    "print('Average precision score, micro-averaged over all classes: {0:0.2f}'\n",
    "      .format(average_precision[\"micro\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = test_datagen.flow_from_directory(test_dir,\n",
    "                                target_size=(224, 224),\n",
    "                                batch_size=10,\n",
    "                                class_mode='categorical')\n",
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = validation_generator.classes\n",
    "predictions = model.predict_generator(validation_generator)\n",
    "y_pred = np.array([np.argmax(x) for x in predictions])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cm = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "ax = sns.heatmap(cm, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Accuracy Graph and Metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# acc = history.history['acc']\n",
    "# val_acc =history.history['val_acc']\n",
    "# loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "\n",
    "# auc = history.history['auc_2']\n",
    "# val_auc = history.history['val_auc_2']\n",
    "\n",
    "\n",
    "\n",
    "# epochs = range(1, len(acc)+1)\n",
    "\n",
    "# plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "# plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "# plt.title('Training and validation accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(epochs, loss, 'bo', label= 'Training loss')\n",
    "# plt.plot(epochs, val_loss, 'b', label = 'Validation loss')\n",
    "# plt.title('Training and validation loss')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(epochs, auc, 'bo', label= 'AUC')\n",
    "# plt.plot(epochs, val_auc, 'b', label = 'AUC loss')\n",
    "# plt.title('Training and validation loss')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "validation_dir=r\"D:\\datasets\\test\"\n",
    "generator = ImageDataGenerator()\n",
    "validation_ds = generator.flow_from_directory(validation_dir,target_size=(224, 224),batch_size=1)\n",
    "\n",
    "# model.evaluate_generator(validation_ds)\n",
    "\n",
    "# Get the names of the 5 classes\n",
    "class_names = validation_ds.class_indices.keys()\n",
    "\n",
    "preds = model.predict(validation_ds)\n",
    "pred_classes = np.argmax(preds, axis=1)\n",
    "\n",
    "true_classes = validation_ds.classes\n",
    "\n",
    "\n",
    "def plot_heatmap(y_true, y_pred, class_names, ax, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(\n",
    "        cm, \n",
    "        annot=True, \n",
    "        square=True, \n",
    "        xticklabels=class_names, \n",
    "        yticklabels=class_names,\n",
    "        fmt='d', \n",
    "        cmap=plt.cm.Blues,\n",
    "        cbar=False,\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "    ax.set_ylabel('True Label', fontsize=12)\n",
    "    ax.set_xlabel('Predicted Label', fontsize=12)\n",
    "\n",
    "fig, (ax1) = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "# plot_heatmap(true_classes, scratch_pred_classes, class_names, ax1, title=\"Custom CNN\")    \n",
    "plot_heatmap(true_classes, pred_classes, class_names, ax1, title=\"Transfer Learning (VGG16) No Fine-Tuning\")    \n",
    "# plot_heatmap(true_classes, vgg_pred_classes_ft, class_names, ax3, title=\"Transfer Learning (VGG16) with Fine-Tuning\")    \n",
    "\n",
    "# fig.suptitle(\"Confusion Matrix Model Comparison\", fontsize=24)\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=1.25)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d6661c79e81cb527c99f5eca452554fb3cfe8b0c1e89b7541cf7c7744c304376"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
